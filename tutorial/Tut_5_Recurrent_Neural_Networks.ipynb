{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjU0K-Jy2STo"
      },
      "source": [
        "# Tutorial 5 - Recurrent Neural Networks\n",
        "\n",
        "This tutorial is split into three parts. Parts A and B were covered in the lecture and focus on Word2Vec and GloVe word embeddings. Sentiment analysis using GloVe embeddings with a simple ANN classifier is the focus of Part B. Part C introduces recurrent neural networks (RNNs) for sentiment analysis and provides sample code for batching of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsDHAKK-6e16"
      },
      "source": [
        "#Part A: Word2Vec and GloVe Vectors\n",
        "We saw how autoencoders are used to learn a latent\n",
        "**embedding space**: an alternative, low-dimensional representation\n",
        "of a set of data with some appealing properties:\n",
        "for example, we saw that interpolating in the latent space\n",
        "is a way of generating new examples. In particular,\n",
        "interpolation in the latent space generates more compelling\n",
        "examples than, say, interpolating in the raw pixel space.\n",
        "\n",
        "The idea of learning an alternative representation/features/*embeddings* of data\n",
        "is a prevalent one in machine learning. Good representations will\n",
        "make downstream tasks (like generating new data, clustering, computing distances) perform much better.\n",
        "\n",
        "With autoencoders, we were able to learn a representation of MNIST digits.\n",
        "In lab 4, we use an autoencoder to learn a representation of a census record.\n",
        "In both cases, we used a model that looks like this:\n",
        "\n",
        "- **Encoder**: data -> embedding\n",
        "- **Decoder**: embedding -> data\n",
        "\n",
        "This type of architecture works well for certain types of data (e.g. images)\n",
        "that are easy to generate, and whose meaning is encoded in the input data\n",
        "representation (e.g. the pixels).\n",
        "\n",
        "But what if we want to train an embedding on words? Words are different\n",
        "from images, in that the meaning of a word is not represented\n",
        "by the letters that make up the word (the same way that the meaning\n",
        "of an image is represented by the pixels that make up the pixel). Instead,\n",
        "the meaning of words comes from how they are used in conjunction with other\n",
        "words.\n",
        "\n",
        "## word2vec models\n",
        "\n",
        "A word2vec model learns embedding of words using the following architecture:\n",
        "\n",
        "- **Encoder**: word -> embedding\n",
        "- **Decoder**: embedding -> nearby words (context)\n",
        "\n",
        "Specific word2vec models differ in the which \"nearby words\" is predicted\n",
        "using the decoder: is it the 3 context words that appeared *before*\n",
        "the input word? Is it the 3 words that appeared *after*? Or is it a combination\n",
        "of the two words that appeared before and two words that appeared after\n",
        "the input word?\n",
        "\n",
        "These models are trained using a large corpus of text: for example the whole\n",
        "of Wikipedia or a large collection of news articles. We won't train our\n",
        "own word2vec models in this course, so we won't talk about the many considerations involved in training a word2vec model.\n",
        "\n",
        "Instead, we will use a set of pre-trained word embeddings. These are embeddings\n",
        "that someone else took the time and computational power to train.\n",
        "One of the most commonly-used pre-trained word embeddings are the **GloVe embeddings**.\n",
        "\n",
        "GloVe is a variation of a word2vec model. Again, the specifics of the algorithm\n",
        "and its training will be beyond the scope of this course.\n",
        "You should think of **GloVe embeddings** similarly to pre-trained AlexNet weights in that they \"may\" provide improvements to the representation of data.\n",
        "\n",
        "More information about GloVe is available here: https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Unlike AlexNet, there are several variations of GloVe embeddings. They\n",
        "differ in the corpus used to train the embedding, and the *size* of the embeddings.\n",
        "\n",
        "## GloVe Embeddings\n",
        "\n",
        "To load pre-trained GloVe embeddings, we'll use a package called `torchtext`.\n",
        "The package `torchtext` contains other useful tools for working with text\n",
        "that we will see later in the course. The documentation for torchtext\n",
        "GloVe vectors are available at: https://torchtext.readthedocs.io/en/latest/vocab.html#glove\n",
        "\n",
        "We'll begin by loading a set of GloVe embeddings. The first time you run the code below, Python will download a large file (862MB) containing the pre-trained embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UORHOkpF6e18"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "# The first time you run this will download a ~823MB file\n",
        "glove = GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "                      dim=50) # embedding size = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I18-A-vX6e2B"
      },
      "source": [
        "Let's look at what the embedding of the word \"car\" looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45MJth3T6e2C"
      },
      "outputs": [],
      "source": [
        "glove['car']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnMtWa6i6e2G"
      },
      "source": [
        "It is a torch tensor with dimension `(50,)`. It is difficult to determine what each\n",
        "number in this embedding means, if anything. However, we know that there is structure\n",
        "in this embedding space. That is, distances in this embedding space is meaningful.\n",
        "\n",
        "## Measuring Distance\n",
        "\n",
        "To explore the structure of the embedding space, it is necessary to introduce\n",
        "a notion of *distance*. You are probably already familiar with the notion\n",
        "of the **Euclidean distance**. The Euclidean distance of two vectors $x = [x_1, x_2, ... x_n]$ and\n",
        "$y = [y_1, y_2, ... y_n]$ is just the 2-norm of their difference $x - y$. We can compute\n",
        "the Euclidean distance between $x$ and $y$:\n",
        "$\\sqrt{\\sum_i (x_i - y_i)^2}$\n",
        "\n",
        "The PyTorch function `torch.norm` computes the 2-norm of a vector for us, so we\n",
        "can compute the Euclidean distance between two vectors like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AF5zD3r6e2H"
      },
      "outputs": [],
      "source": [
        "x = glove['cat']\n",
        "y = glove['dog']\n",
        "torch.norm(y - x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9d4OENG6e2L"
      },
      "outputs": [],
      "source": [
        "torch.norm(glove['good'] - glove['bad'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYYTNoJd6e2P"
      },
      "outputs": [],
      "source": [
        "torch.norm(glove['good'] - glove['water'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agzsKxtB6e2S"
      },
      "outputs": [],
      "source": [
        "torch.norm(glove['good'] - glove['well'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja6wXHUR6e2f"
      },
      "outputs": [],
      "source": [
        "torch.norm(glove['good'] - glove['perfect'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5yo0nRA6e2j"
      },
      "outputs": [],
      "source": [
        "torch.norm(glove['good'] - glove['bravo'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L68vJPyp6e2l"
      },
      "source": [
        "An alternative measure of distance is the **Cosine Similarity**.\n",
        "The cosine similarity measures the *angle* between two vectors,\n",
        "and has the property that it only considers the *direction* of the\n",
        "vectors, not their magnitudes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQGqLuLo6e2m"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1., 1., 1.]).unsqueeze(0)\n",
        "y = torch.tensor([2., 2., -2.]).unsqueeze(0)\n",
        "torch.cosine_similarity(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1iL4y9G6e2p"
      },
      "source": [
        "The cosine similarity is a *similarity* measure rather than a *distance* measure:\n",
        "The larger the similarity,\n",
        "the \"closer\" the word embeddings are to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq5TjyjM6e2q"
      },
      "outputs": [],
      "source": [
        "x = glove['cat']\n",
        "y = glove['dog']\n",
        "torch.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isp4ENaP6e2s"
      },
      "outputs": [],
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['bad'].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KT6t--m6e2v"
      },
      "outputs": [],
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['well'].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrrYJjtg6e2y"
      },
      "outputs": [],
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['perfect'].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2j5GhxN6e21"
      },
      "outputs": [],
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['bravo'].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2prXo1u16e28"
      },
      "source": [
        "## Word Similarity\n",
        "\n",
        "Now that we have a notion of distance in our embedding space, we can talk\n",
        "about words that are \"close\" to each other in the embedding space.\n",
        "For now, let's use Euclidean distances to look at how close various words\n",
        "are to the word \"cat\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjOT20nu6e29"
      },
      "outputs": [],
      "source": [
        "word = 'cat'\n",
        "other = ['pet', 'dog', 'bike', 'kitten', 'puppy', 'kite', 'computer', 'neuron']\n",
        "for w in other:\n",
        "    dist = torch.norm(glove[word] - glove[w]) # euclidean distance\n",
        "    print(w, float(dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8xuChOT6e3B"
      },
      "source": [
        "In fact, we can look through our entire vocabulary for words that are closest\n",
        "to a point in the embedding space -- for example, we can look for words\n",
        "that are closest to another word like \"cat\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyIdY_Ol6e3C"
      },
      "outputs": [],
      "source": [
        "def print_closest_words(vec, n=5):\n",
        "    dists = torch.norm(glove.vectors - vec, dim=1)     # compute distances to all words\n",
        "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) # sort by distance\n",
        "    for idx, difference in lst[1:n+1]:                         # take the top n\n",
        "        print(glove.itos[idx], difference)\n",
        "\n",
        "print_closest_words(glove[\"cat\"], n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPiEs8Dx6e3G"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['nurse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKQmaqwe6e3O"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['computer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nEYq4UB6e3V"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['elizabeth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRyHGVsU6e3Z"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['michael'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-SDsoL46e3c"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['bravo'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZefA2jV86e3e"
      },
      "source": [
        "We could also look at which words are closest to the midpoints of two words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbAyMQjw6e3f"
      },
      "outputs": [],
      "source": [
        "print_closest_words((glove['happy'] + glove['sad']) / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZaSgfTm6e3l"
      },
      "outputs": [],
      "source": [
        "print_closest_words((glove['lake'] + glove['building']) / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fDh7JSr6e3p"
      },
      "outputs": [],
      "source": [
        "print_closest_words((glove['bravo'] + glove['michael']) / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NZ5vxDt6e3s"
      },
      "outputs": [],
      "source": [
        "print_closest_words((glove['one'] + glove['ten']) / 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4kJq7qN6e3w"
      },
      "source": [
        "## Analogies\n",
        "\n",
        "One surprising aspect of GloVe vectors is that the *directions* in the\n",
        "embedding space can be meaningful. The structure of the GloVe vectors\n",
        "certain analogy-like relationship like this tend to hold:\n",
        "\n",
        "$$ king - man + woman \\approx queen $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ2AXRTo6e3x"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['king'] - glove['man'] + glove['woman'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-HjB0406e30"
      },
      "source": [
        "We get reasonable answers like \"queen\", \"throne\" and the name of\n",
        "our current queen.\n",
        "\n",
        "We can likewise flip the analogy around:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2HhfeRs6e32"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['queen'] - glove['woman'] + glove['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXHR54mM6e38"
      },
      "source": [
        "Or, try a different but related analogies along the gender axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXqfqaOW6e3-"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['king'] - glove['prince'] + glove['princess'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlokVrC06e4E"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['uncle'] - glove['man'] + glove['woman'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLhkBKcq6e4I"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['grandmother'] - glove['mother'] + glove['father'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfvleT6A6e4L"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['old'] - glove['young'] + glove['father'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhO_pa1r6e4P"
      },
      "source": [
        "We can move an embedding towards the direction of \"goodness\" or \"badness\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5wYLXZf6e4P"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['good'] - glove['bad'] + glove['programmer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9plKEy76e4S"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['bad'] - glove['good'] + glove['programmer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRoLUQVu6e4W"
      },
      "source": [
        "## Biased in Word Vectors\n",
        "\n",
        "Machine learning models have an air of \"fairness\" about them, since models\n",
        "make decisions without human intervention. However, models can and do learn\n",
        "whatever bias is present in the training data!\n",
        "\n",
        "GloVe vectors seems innocuous enough: they are just representations of\n",
        "words in some embedding space. Even so, we'll show that the structure\n",
        "of the GloVe vectors encodes the everyday biases present in the texts\n",
        "that they are trained on.\n",
        "\n",
        "We'll start with an example analogy:\n",
        "\n",
        "$$doctor - man + woman \\approx ??$$\n",
        "\n",
        "Let's use GloVe vectors to find the answer to the above analogy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Icjm4OIT6e4X"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['doctor'] - glove['man'] + glove['woman'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR-lVcpe6e4a"
      },
      "source": [
        "The $$doctor - man + woman \\approx nurse$$ analogy is very concerning.\n",
        "Just to verify, the same result does not appear if we flip the gender terms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7_Jo_0X6e4a"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['doctor'] - glove['woman'] + glove['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDarqJp6e4d"
      },
      "source": [
        "We see similar types of gender bias with other professions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_ZzBBpl6e4d"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['programmer'] - glove['man'] + glove['woman'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icCpHxi66e4g"
      },
      "source": [
        "Beyond the first result, none of the other words are even related to\n",
        "programming! In contrast, if we flip the gender terms, we get very\n",
        "different results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW9IjXqI6e4g"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['programmer'] - glove['woman'] + glove['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtx2n7Nj6e4i"
      },
      "source": [
        "Here are the results for \"engineer\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dFlol9D6e4j"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['engineer'] - glove['man'] + glove['woman'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV-XgFbD6e4l"
      },
      "outputs": [],
      "source": [
        "print_closest_words(glove['engineer'] - glove['woman'] + glove['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBaKH4os6dym"
      },
      "source": [
        "#Part B: GloVe vectors for sentiment analysis\n",
        "## Sentiment Analysis\n",
        "\n",
        "**Sentiment Analysis** is the problem of identifying the writer's sentiment given a piece of text. Sentiment Analysis can be applied to movie reviews, emails, tweets, and much more.\n",
        "\n",
        "Rudimentary forms of **sentiment analysis** might involve scoring each\n",
        "word on a scale from \"sad\" to \"happy\", then averaging the \"happiness score\" of the words in a piece of text. This technique has obvious drawbacks: it won't be able to handle negation, sarcasm, or any complex syntactical form. We can do better.\n",
        "\n",
        "We will perform sentiment analysis using the Sentiment140 data set, which contains tweets with either a positive or negative emoticon. Our goal is to determine whether which type of emoticon the tweet (with the emoticon removed) contained. The dataset was actually collected by a group of students, just like you, who were working on their machine learning project, just like you are doing.\n",
        "\n",
        "This tutorial will require that you download the file \"*training.1600000.processed.noemoticon.csv*\" from Quercus (or from http://help.sentiment140.com/) and upload it to your Google Drive. Please make sure to mount your Drive and that you are able to load the file, otherwise the sample code will not work as intended.\n",
        "\n",
        "Let's look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNXtT6iCVsrY"
      },
      "outputs": [],
      "source": [
        "#setup Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwgOTTGD6dyp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# file location (make sure to use your file location)\n",
        "file_dir = '/content/drive/My Drive/Colab Notebooks/Lab 5/'\n",
        "\n",
        "# load csv file\n",
        "def get_data():\n",
        "    return csv.reader(open(file_dir + \"training.1600000.processed.noemoticon.csv\",\"rt\", encoding=\"latin-1\"))\n",
        "\n",
        "# print only the first tweet\n",
        "for i, line in enumerate(get_data()):\n",
        "    if line[0] != '0':\n",
        "        print(line[0], line[-1])\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQVuCUQH6dys"
      },
      "source": [
        "The columns we care about is the first one and the last one. The first column is the\n",
        "label (the label `0` means \"sad\" tweet, `4` means \"happy\" tweet), and the last column\n",
        "contains the tweet. Our task is to predict the sentiment of the tweet given the text.\n",
        "\n",
        "The approach today is as follows, for each tweet:\n",
        "\n",
        "1. We will split the text into words. We will do so by splitting at all whitespace\n",
        "   characters. There are better ways to perform the split, but let's keep our\n",
        "   dependencies light.\n",
        "2. We will look up the GloVe embedding of each word.\n",
        "   Words that do not have a GloVe vector will be ignored.\n",
        "3. We will sum up all the embeddings to get an embedding for an entire tweet.\n",
        "4. Finally, we will use a fully-connected neural network\n",
        "   to predict whether the tweet has positive or negative sentiment.\n",
        "\n",
        "First, let's sanity check that there are enough words for us to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzUmQaAI6dyw"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
        "\n",
        "def split_tweet(tweet):\n",
        "    # separate punctuations\n",
        "    tweet = tweet.replace(\".\", \" . \") \\\n",
        "                 .replace(\",\", \" , \") \\\n",
        "                 .replace(\";\", \" ; \") \\\n",
        "                 .replace(\"?\", \" ? \")\n",
        "    return tweet.lower().split()\n",
        "\n",
        "split_tweet(\"hello; don't you know?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXfvRbMSgGpJ"
      },
      "outputs": [],
      "source": [
        "# verify that each tweet has a reasonable number of words\n",
        "# that have GloVe embeddings\n",
        "for i, line in enumerate(get_data()):\n",
        "    if i > 30:\n",
        "        break\n",
        "    print(sum(int(w in glove.stoi) for w in split_tweet(line[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMijpmBs6dyz"
      },
      "source": [
        "Looks like each tweet has at least one word that has an embedding.\n",
        "\n",
        "Now, steps 1-3 from above can be done ahead of time, just like the transfer learning\n",
        "portion of Lab 3. So, we will write a function that will take the tweets data\n",
        "file, computes the tweet embeddings, and splits the data into train/validation/test.\n",
        "\n",
        "We will only use $\\frac{1}{59}$ of the data in the file, so that this demo runs\n",
        "relatively quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO-mRzST6dy0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_tweet_vectors(glove_vector):\n",
        "    train, valid, test = [], [], []\n",
        "    for i, line in enumerate(get_data()):\n",
        "        tweet = line[-1]\n",
        "        if i % 59 == 0:\n",
        "            # obtain an embedding for the entire tweet\n",
        "            tweet_emb = sum(glove_vector[w] for w in split_tweet(tweet))\n",
        "            # generate a label: 1 = happy, 0 = sad\n",
        "            label = torch.tensor(int(line[0] == \"4\")).long()\n",
        "            # place the data set in either the training, validation, or test set\n",
        "            if i % 5 < 3:\n",
        "                train.append((tweet_emb, label)) # 60% training\n",
        "            elif i % 5 == 4:\n",
        "                valid.append((tweet_emb, label)) # 20% validation\n",
        "            else:\n",
        "                test.append((tweet_emb, label)) # 20% test\n",
        "    return train, valid, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Dh4nem6dy3"
      },
      "source": [
        "I'm making the `glove_vector` a parameter so that we can test the effect\n",
        "of using a higher dimensional GloVe\n",
        "embedding later. Now, let's get our training, validation, and test set.\n",
        "The format is what `torch.utils.data.DataLoader` expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0fMybj86dy4"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
        "\n",
        "train, valid, test = get_tweet_vectors(glove)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5V051Cw6dy6"
      },
      "source": [
        "Now, our actual training script! Note that will we use `CrossEntropyLoss`,\n",
        "have two neurons in the final layer of our output layer, and use softmax instead of\n",
        "a sigmoid activation. This is different from our choice in the earlier weeks!\n",
        "Typically, machine learning practitioners will choose to use two output\n",
        "neurons instead of one, even in a binary classification task. The reason is that\n",
        "an extra neuron adds some more parameters to the network, and makes the network\n",
        "a little easier to train (performs better)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9l9BR5v6dy7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_network(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    losses, train_acc, valid_acc = [], [], []\n",
        "    epochs = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for tweets, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(tweets)\n",
        "            loss = criterion(pred, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        losses.append(float(loss))\n",
        "        if epoch % 5 == 4:\n",
        "            epochs.append(epoch)\n",
        "            train_acc.append(get_accuracy(model, train_loader))\n",
        "            valid_acc.append(get_accuracy(model, valid_loader))\n",
        "            print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "                epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    correct, total = 0, 0\n",
        "    for tweets, labels in data_loader:\n",
        "        output = model(tweets)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += labels.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarFbhzt6dy-"
      },
      "source": [
        "As for the actual mode, we will start with a 3-layer neural network.\n",
        "We won't create our own class since this is a fairly straightforward neural\n",
        "network, so an `nn.Sequential` object will do.\n",
        "Let's build and train our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv9IctEO6dy_"
      },
      "outputs": [],
      "source": [
        "mymodel = nn.Sequential(nn.Linear(50, 30),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(30, 10),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(10, 2))\n",
        "train_network(mymodel, train_loader, valid_loader, num_epochs=100, learning_rate=1e-4)\n",
        "print(\"Final test accuracy:\", get_accuracy(mymodel, test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhzOWZST6dzC"
      },
      "outputs": [],
      "source": [
        "def test_model(model, glove_vector, tweet):\n",
        "    emb = sum(glove_vector[w] for w in split_tweet(tweet))\n",
        "    out = mymodel(emb.unsqueeze(0))\n",
        "    pred = out.max(1, keepdim=True)[1]\n",
        "    return pred\n",
        "\n",
        "test_model(mymodel, glove, \"very happy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvNr30LO6dzE"
      },
      "outputs": [],
      "source": [
        "test_model(mymodel, glove, \"This is a terrible tragedy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ef-BznK6dzQ"
      },
      "outputs": [],
      "source": [
        "test_model(mymodel, glove, \"okay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WHkOGUz6dzT"
      },
      "source": [
        "Note that the model does not perform very well, but it does get it right from time to time. There are a number of things we could try to improve the performance, for example changing the number of hidden units, number of layers, or change the dimension of the Glove embeddings.\n",
        "\n",
        "Another option is to use a more powerful architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m-MCuRr6lAG"
      },
      "source": [
        "#Part C: Recurrent Neural Networks\n",
        "\n",
        "One of the drawbacks of the previous approach is that the order of\n",
        "words is lost. The tweets \"the cat likes the dog\" and \"the dog likes the cat\"\n",
        "would have the exact same embedding, even though the sentences have different\n",
        "meanings.\n",
        "\n",
        "For this part we will use a **recurrent neural network**. We will treat each tweet\n",
        "as a **sequence** of words. Like before, we will use GloVe embeddings as inputs\n",
        "to the recurrent network. (As a sidenote, not all recurrent neural networks use\n",
        "word embeddings as input. If we had a small enough vocabulary, we could have used\n",
        "a one-hot embedding of the words.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi_v650L6lAJ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# file location (make sure to use your file location)\n",
        "file_dir = '/content/drive/My Drive/Colab Notebooks/Lab 5/'\n",
        "\n",
        "def get_data():\n",
        "    return csv.reader(open(file_dir + \"training.1600000.processed.noemoticon.csv\",\"rt\", encoding=\"latin-1\"))\n",
        "\n",
        "def split_tweet(tweet):\n",
        "    # separate punctuations\n",
        "    tweet = tweet.replace(\".\", \" . \") \\\n",
        "                 .replace(\",\", \" , \") \\\n",
        "                 .replace(\";\", \" ; \") \\\n",
        "                 .replace(\"?\", \" ? \")\n",
        "    return tweet.lower().split()\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50, max_vectors=10000) # use 10k most common words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSTiHPJA6lAM"
      },
      "source": [
        "Since we are going to store the individual words in a tweet,\n",
        "we will defer looking up the word embeddings.\n",
        "Instead, we will store the **index** of each word in a PyTorch tensor.\n",
        "Our choice is the most memory-efficient, since it takes fewer bits to\n",
        "store an integer index than a 50-dimensional vector or a word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MoEcSg66lAN"
      },
      "outputs": [],
      "source": [
        "def get_tweet_words(glove_vector):\n",
        "    train, valid, test = [], [], []\n",
        "    for i, line in enumerate(get_data()):\n",
        "        if i % 29 == 0:\n",
        "            tweet = line[-1]\n",
        "            idxs = [glove_vector.stoi[w]        # lookup the index of word\n",
        "                    for w in split_tweet(tweet)\n",
        "                    if w in glove_vector.stoi] # keep words that has an embedding\n",
        "            if not idxs: # ignore tweets without any word with an embedding\n",
        "                continue\n",
        "            idxs = torch.tensor(idxs) # convert list to pytorch tensor\n",
        "            label = torch.tensor(int(line[0] == \"4\")).long()\n",
        "            if i % 5 < 3:\n",
        "                train.append((idxs, label))\n",
        "            elif i % 5 == 4:\n",
        "                valid.append((idxs, label))\n",
        "            else:\n",
        "                test.append((idxs, label))\n",
        "    return train, valid, test\n",
        "\n",
        "train, valid, test = get_tweet_words(glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH4fypPq6lAQ"
      },
      "source": [
        "Here's what an element of the training set looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz3FWzVB6lAR"
      },
      "outputs": [],
      "source": [
        "tweet, label = train[0]\n",
        "print(tweet)\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUl6xwqt6lAU"
      },
      "source": [
        "Unlike in the past, each element of the training set will have a\n",
        "different shape. The difference will present some difficulties when\n",
        "we discuss batching later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_GUKqt76lAV"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    tweet, label = train[i]\n",
        "    print(tweet.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emg79Nia6lAY"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "We are also going to use an `nn.Embedding` layer, instead of using the variable\n",
        "`glove` directly. The reason is that the `nn.Embedding` layer allows us look up\n",
        "the embeddings of multiple words simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCb12CCp6lAZ"
      },
      "outputs": [],
      "source": [
        "glove_emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "\n",
        "# Example: we use the forward function of glove_emb to lookup the\n",
        "# embedding of each word in `tweet`\n",
        "tweet_emb = glove_emb(tweet)\n",
        "tweet_emb.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRczqTwm6lAc"
      },
      "source": [
        "## Recurrent Neural Network Module\n",
        "\n",
        "PyTorch has variations of recurrent neural network modules.\n",
        "These modules computes the following:\n",
        "\n",
        "$$hidden = updatefn(hidden, input)$$\n",
        "$$output = outputfn(hidden)$$\n",
        "\n",
        "These modules are more complex and less intuitive than the usual\n",
        "neural network layers, so let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaQnkloA6lAd"
      },
      "outputs": [],
      "source": [
        "rnn_layer = nn.RNN(input_size=50,    # dimension of the input repr\n",
        "                   hidden_size=50,   # dimension of the hidden units\n",
        "                   batch_first=True) # input format is [batch_size, seq_len, repr_dim]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McnkXSD06lAf"
      },
      "source": [
        "Now, let's try and run this untrained `rnn_layer` on `tweet_emb`.\n",
        "We will need to add an extra dimension to `tweet_emb` to account for\n",
        "batching. We will also need to initialize a set of hidden units of size\n",
        "`[batch_size, 1, repr_dim]`, to be used for the *first* set of computations.\n",
        "\n",
        "![](imgs/rnn.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46ARRDO76lAg"
      },
      "outputs": [],
      "source": [
        "tweet_input = tweet_emb.unsqueeze(0) # add the batch_size dimension\n",
        "h0 = torch.zeros(1, 1, 50)           # initial hidden state\n",
        "out, last_hidden = rnn_layer(tweet_input, h0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlHsKlu66lAj"
      },
      "source": [
        "We don't technically have to explictly provide the initial hidden state,\n",
        "if we want to use an initial state of zeros. Just for today, we will be\n",
        "explicit about the hidden states that we provide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt5DhCRW6lAk"
      },
      "outputs": [],
      "source": [
        "out2, last_hidden2 = rnn_layer(tweet_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFF1ZygN6lAn"
      },
      "source": [
        "Now, let's look at the output and hidden dimensions that we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQG1B0Vj6lAo"
      },
      "outputs": [],
      "source": [
        "print(out.shape)\n",
        "print(last_hidden.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ju9XGxQ6lAr"
      },
      "source": [
        "The shape of the hidden units is the same as our initial `h0`.\n",
        "The variable `out`, though, has the same shape as our `input`.\n",
        "The variable contains the concatenation of all of the output units\n",
        "for each word (i.e. at each time point).\n",
        "\n",
        "Normally, we only care about the output at the **final** time point,\n",
        "which we can extract like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3gdskfq6lAr"
      },
      "outputs": [],
      "source": [
        "out[:,-1,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5StyRJQL6lAu"
      },
      "source": [
        "This tensor summarizes the entire tweet, and can be used as an input\n",
        "to a classifier.\n",
        "\n",
        "## Building a Model\n",
        "\n",
        "Let's put both the embedding layer, the RNN and the classifier into one model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAZ928tH6lAv"
      },
      "outputs": [],
      "source": [
        "class TweetRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(TweetRNN, self).__init__()\n",
        "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        x = self.emb(x)\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "model = TweetRNN(50, 50, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkZVSHki6lAx"
      },
      "source": [
        "We should be able to train this model similar to any other model that we have trained before. However, there is one caveat that we have been avoiding this entire time, **batching**.\n",
        "\n",
        "## Batching\n",
        "\n",
        "Unfortunately, we will not be able to use `DataLoader` with a\n",
        "`batch_size` of greater than one. This is because each tweet has\n",
        "a different shaped tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fdPxVzz6lAy"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    tweet, label = train[i]\n",
        "    print(tweet.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9V-af5Q6lA1"
      },
      "source": [
        "PyTorch implementation of `DataLoader` class expects all data samples\n",
        "to have the same shape. So, if we create a DataLoader like below,\n",
        "it will throw an error when we try to iterate over its elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvCWcP3n6lA2"
      },
      "outputs": [],
      "source": [
        "#will_fail = torch.utils.data.DataLoader(train, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV5LmijX6lA5"
      },
      "source": [
        "So, we will need a different way of batching.\n",
        "\n",
        "One strategy is to **pad shorter sequences with zero inputs**, so that\n",
        "every sequence is the same length. The following PyTorch utilities\n",
        "are helpful.\n",
        "\n",
        "- `torch.nn.utils.rnn.pad_sequence`\n",
        "- `torch.nn.utils.rnn.pad_packed_sequence`\n",
        "- `torch.nn.utils.rnn.pack_sequence`\n",
        "- `torch.nn.utils.rnn.pack_padded_sequence`\n",
        "\n",
        "(Actually, there are more powerful helpers in the `torchtext` module\n",
        "that we will use in Lab 5. We'll stick to these in this demo, so that\n",
        "you can see what's actually going on under the hood.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td8JCx6H6lA6"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "tweet_padded = pad_sequence([tweet for tweet, label in train[:10]],\n",
        "                            batch_first=True)\n",
        "print(tweet_padded.shape)\n",
        "print(tweet_padded[0:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ0DmJ-C6lA9"
      },
      "source": [
        "Now, we can pass multiple tweets in a batch through the RNN at once!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2-AUHrx6lA-"
      },
      "outputs": [],
      "source": [
        "out = model(tweet_padded)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd7YuKn86lBA"
      },
      "source": [
        "One issue we overlooked was that in our `TweetRNN` model, we always\n",
        "take the **last output unit** as input to the final classifier. Now\n",
        "that we are padding the input sequences, we should really be using\n",
        "the output at a previous time step. Recurrent neural networks therefore\n",
        "require much more record keeping than ANNs or even CNNs.\n",
        "\n",
        "There is yet another problem:\n",
        "the longest tweet has many, many more words than the shortest.\n",
        "Padding tweets so that every tweet has the same length as the longest\n",
        "tweet is impractical. Padding tweets in a mini-batch, however, is much\n",
        "more reasonable.\n",
        "\n",
        "In practice, practitioners will batch together tweets with the same\n",
        "length. For simplicity, we will do the same. We will implement a (more or less)\n",
        "straightforward way to batch tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhS_q3E_6lBB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class TweetBatcher:\n",
        "    def __init__(self, tweets, batch_size=32, drop_last=False):\n",
        "        # store tweets by length\n",
        "        self.tweets_by_length = {}\n",
        "        for words, label in tweets:\n",
        "            # compute the length of the tweet\n",
        "            wlen = words.shape[0]\n",
        "            # put the tweet in the correct key inside self.tweet_by_length\n",
        "            if wlen not in self.tweets_by_length:\n",
        "                self.tweets_by_length[wlen] = []\n",
        "            self.tweets_by_length[wlen].append((words, label),)\n",
        "\n",
        "        #  create a DataLoader for each set of tweets of the same length\n",
        "        self.loaders = {wlen : torch.utils.data.DataLoader(\n",
        "                                    tweets,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=True,\n",
        "                                    drop_last=drop_last) # omit last batch if smaller than batch_size\n",
        "            for wlen, tweets in self.tweets_by_length.items()}\n",
        "\n",
        "    def __iter__(self): # called by Python to create an iterator\n",
        "        # make an iterator for every tweet length\n",
        "        iters = [iter(loader) for loader in self.loaders.values()]\n",
        "        while iters:\n",
        "            # pick an iterator (a length)\n",
        "            im = random.choice(iters)\n",
        "            try:\n",
        "                yield next(im)\n",
        "            except StopIteration:\n",
        "                # no more elements in the iterator, remove it\n",
        "                iters.remove(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB9bCg7-6lBH"
      },
      "source": [
        "Let's take a look at our batcher in action. We will set `drop_last` to be true for training,\n",
        "so that all of our batches have exactly the same size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3JAsR4S6lBJ"
      },
      "outputs": [],
      "source": [
        "for i, (tweets, labels) in enumerate(TweetBatcher(train, drop_last=True)):\n",
        "    if i > 20: break\n",
        "    print(tweets.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV8CYnwQ6lBM"
      },
      "source": [
        "Just to verify that our batching is reasonable, here is a modification of the\n",
        "`get_accuracy` function we wrote last time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5XM9ewr6lBN"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    correct, total = 0, 0\n",
        "    for tweets, labels in data_loader:\n",
        "        output = model(tweets)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += labels.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "test_loader = TweetBatcher(test, batch_size=64, drop_last=False)\n",
        "get_accuracy(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ZsJhdP6lBP"
      },
      "source": [
        "Our training code will also be very similar to the code we wrote last time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tPj9gwy6lBQ"
      },
      "outputs": [],
      "source": [
        "def train_rnn_network(model, train, valid, num_epochs=5, learning_rate=1e-5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    losses, train_acc, valid_acc = [], [], []\n",
        "    epochs = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for tweets, labels in train:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(tweets)\n",
        "            loss = criterion(pred, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        losses.append(float(loss))\n",
        "\n",
        "        epochs.append(epoch)\n",
        "        train_acc.append(get_accuracy(model, train_loader))\n",
        "        valid_acc.append(get_accuracy(model, valid_loader))\n",
        "        print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "              epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmB_73On6lBT"
      },
      "source": [
        "Let's train our model. Note that there will be some inaccuracies in computing the training loss.\n",
        "We are dropping some data from the training set by setting `drop_last=True`. Again, the choice is\n",
        "not ideal, but simplifies our code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym4cBxAP6lBU"
      },
      "outputs": [],
      "source": [
        "model = TweetRNN(50, 50, 2)\n",
        "train_loader = TweetBatcher(train, batch_size=64, drop_last=True)\n",
        "valid_loader = TweetBatcher(valid, batch_size=64, drop_last=False)\n",
        "train_rnn_network(model, train_loader, valid_loader, num_epochs=20, learning_rate=2e-4)\n",
        "get_accuracy(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z86LNm5C6lBW"
      },
      "source": [
        "The hidden size and the input embedding size don't have to be the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_RTLW9r6lBX"
      },
      "outputs": [],
      "source": [
        "model = TweetRNN(50, 100, 2)\n",
        "train_rnn_network(model, train_loader, valid_loader, num_epochs=20, learning_rate=2e-4)\n",
        "get_accuracy(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbkydKtxyvH_"
      },
      "source": [
        "##### Sentiment Analysis on New Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi61Uk3lz0Ju"
      },
      "outputs": [],
      "source": [
        "def get_new_tweet(glove_vector, sample_tweet):\n",
        "    tweet = sample_tweet\n",
        "    idxs = [glove_vector.stoi[w]        # lookup the index of word\n",
        "            for w in split_tweet(tweet)\n",
        "            if w in glove_vector.stoi] # keep words that has an embedding\n",
        "    idxs = torch.tensor(idxs) # convert list to pytorch tensor\n",
        "    return idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLEIMbmj2qI5"
      },
      "outputs": [],
      "source": [
        "new_tweet = get_new_tweet(glove, \"This is a terrible tragedy\")\n",
        "print(new_tweet.shape)\n",
        "\n",
        "out = torch.sigmoid(model(new_tweet.unsqueeze(0)))\n",
        "pred = out.max(1, keepdim=True)[1]\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyx3J5H7p6RQ"
      },
      "outputs": [],
      "source": [
        "new_tweet = get_new_tweet(glove, \"This is the best day of my life\")\n",
        "print(new_tweet.shape)\n",
        "\n",
        "out = torch.sigmoid(model(new_tweet.unsqueeze(0)))\n",
        "pred = out.max(1, keepdim=True)[1]\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HpLnBSFqDSo"
      },
      "source": [
        "Sentiment analysis is not a straight forward problem and it's impressive that without too much tunning we are able to get validation accuracy close to 70%. There are many ways that we can improve our performance:\n",
        "\n",
        "*   Tune hyperparameters\n",
        "*   Use all of the available data\n",
        "*   Apply more advanced RNN architectures (ex. LSTM and GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnMBwyGJ6lBs"
      },
      "outputs": [],
      "source": [
        "class TweetLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(TweetLSTM, self).__init__()\n",
        "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        x = self.emb(x)\n",
        "        # Set an initial hidden state and cell state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the LSTM\n",
        "        out, _ = self.rnn(x, (h0, c0))\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "model = TweetLSTM(50, 50, 2)\n",
        "train_rnn_network(model, train_loader, valid_loader, num_epochs=20, learning_rate=2e-5)\n",
        "get_accuracy(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}